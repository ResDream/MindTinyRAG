{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bfcc87-8cb7-4bf3-8a20-20ac1753b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/mindspore-lab/mindnlp.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06e5674-b9a0-4803-a73a-2102ad77f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd mindnlp\n",
    "!git checkout ef64a3b83097c9578bb0d5326f905beeb5b50e1d\n",
    "!bash scripts/build_and_reinstall.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46182796-2c88-466e-a248-09427157d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c511e6-1d0f-49ca-8776-be0953ef4ad9",
   "metadata": {},
   "source": [
    "# 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902c08bc-1eb6-4062-83f2-c6bae74c9ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import markdown\n",
    "import json\n",
    "import tiktoken\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "from copy import copy\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from mindspore import Tensor\n",
    "\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06693aa6-5624-4b80-9021-8fb680c29713",
   "metadata": {},
   "source": [
    "# 2. 读取文件\n",
    "1. 读取文件：读取对应文件夹下所有文件。\n",
    "\n",
    "2. 提取内容：判断文件类型，设计提取内容方式，实现多种格式统一化处理。\n",
    "\n",
    "3. 分块：采用基于最大 token 长度和覆盖内容的逻辑分割长文本，确保段落间的语义连续性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d07c2da-9f7f-4f21-b68d-1508625a4ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadFiles:\n",
    "    \"\"\"\n",
    "    class to read files\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path: str) -> None:\n",
    "        self._path = path\n",
    "        self.file_list = self.get_files()\n",
    "    \n",
    "    @classmethod\n",
    "    def read_pdf(cls, file_path: str):\n",
    "        # 读取PDF文件\n",
    "        with open(file_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page_num in range(len(reader.pages)):\n",
    "                text += reader.pages[page_num].extract_text()\n",
    "            return text\n",
    "\n",
    "    @classmethod\n",
    "    def read_markdown(cls, file_path: str):\n",
    "        # 读取Markdown文件\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            md_text = file.read()\n",
    "            html_text = markdown.markdown(md_text)\n",
    "            # 使用BeautifulSoup从HTML中提取纯文本\n",
    "            soup = BeautifulSoup(html_text, 'html.parser')\n",
    "            plain_text = soup.get_text()\n",
    "            # 使用正则表达式移除网址链接\n",
    "            text = re.sub(r'http\\S+', '', plain_text) \n",
    "            return text\n",
    "\n",
    "    @classmethod\n",
    "    def read_text(cls, file_path: str):\n",
    "        # 读取文本文件\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    \n",
    "    def get_files(self):\n",
    "        # args：dir_path，目标文件夹路径\n",
    "        file_list = []\n",
    "        for filepath, dirnames, filenames in os.walk(self._path):\n",
    "            # os.walk 函数将递归遍历指定文件夹\n",
    "            for filename in filenames:\n",
    "                # 通过后缀名判断文件类型是否满足要求\n",
    "                if filename.endswith(\".md\"):\n",
    "                    # 如果满足要求，将其绝对路径加入到结果列表\n",
    "                    file_list.append(os.path.join(filepath, filename))\n",
    "                elif filename.endswith(\".txt\"):\n",
    "                    file_list.append(os.path.join(filepath, filename))\n",
    "                elif filename.endswith(\".pdf\"):\n",
    "                    file_list.append(os.path.join(filepath, filename))\n",
    "        return file_list\n",
    "\n",
    "    def get_content(self, max_token_len: int = 600, cover_content: int = 150):\n",
    "        docs = []\n",
    "        # 读取文件内容\n",
    "        for file in self.file_list:\n",
    "            content = self.read_file_content(file)\n",
    "            chunk_content = self.get_chunk(\n",
    "                content, max_token_len=max_token_len, cover_content=cover_content)\n",
    "            docs.extend(chunk_content)\n",
    "        return docs\n",
    "\n",
    "    @classmethod\n",
    "    def get_chunk(cls, text: str, max_token_len: int = 600, cover_content: int = 150):\n",
    "        chunk_text = []\n",
    "\n",
    "        curr_len = 0\n",
    "        curr_chunk = ''\n",
    "\n",
    "        token_len = max_token_len - cover_content\n",
    "        lines = text.splitlines()  # 假设以换行符分割文本为行\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.replace(' ', '')\n",
    "            line_len = len(enc.encode(line))\n",
    "            if line_len > max_token_len:\n",
    "                # 如果单行长度就超过限制，则将其分割成多个块\n",
    "                num_chunks = (line_len + token_len - 1) // token_len\n",
    "                for i in range(num_chunks):\n",
    "                    start = i * token_len\n",
    "                    end = start + token_len\n",
    "                    # 避免跨单词分割\n",
    "                    while not line[start:end].rstrip().isspace():\n",
    "                        start += 1\n",
    "                        end += 1\n",
    "                        if start >= line_len:\n",
    "                            break\n",
    "                    curr_chunk = curr_chunk[-cover_content:] + line[start:end]\n",
    "                    chunk_text.append(curr_chunk)\n",
    "                # 处理最后一个块\n",
    "                start = (num_chunks - 1) * token_len\n",
    "                curr_chunk = curr_chunk[-cover_content:] + line[start:end]\n",
    "                chunk_text.append(curr_chunk)\n",
    "                \n",
    "            if curr_len + line_len <= token_len:\n",
    "                curr_chunk += line\n",
    "                curr_chunk += '\\n'\n",
    "                curr_len += line_len\n",
    "                curr_len += 1\n",
    "            else:\n",
    "                chunk_text.append(curr_chunk)\n",
    "                curr_chunk = curr_chunk[-cover_content:]+line\n",
    "                curr_len = line_len + cover_content\n",
    "\n",
    "        if curr_chunk:\n",
    "            chunk_text.append(curr_chunk)\n",
    "\n",
    "        return chunk_text\n",
    "\n",
    "    @classmethod\n",
    "    def read_file_content(cls, file_path: str):\n",
    "        # 根据文件扩展名选择读取方法\n",
    "        if file_path.endswith('.pdf'):\n",
    "            return cls.read_pdf(file_path)\n",
    "        elif file_path.endswith('.md'):\n",
    "            return cls.read_markdown(file_path)\n",
    "        elif file_path.endswith('.txt'):\n",
    "            return cls.read_text(file_path)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file type\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f89fac4-2c0f-4392-9204-7cedc9c2b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ReadFiles('./data').get_content(max_token_len=600, cover_content=150)  # 获得data目录下的所有文件内容并分割\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1d4441-f09e-4737-89df-fa146be74c30",
   "metadata": {},
   "source": [
    "# 3. 设计Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "597af364-5034-4848-91ff-17d37ed8b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseEmbeddings:\n",
    "    \"\"\"\n",
    "    Base class for embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path: str, is_api: bool) -> None:\n",
    "        self.path = path\n",
    "        self.is_api = is_api\n",
    "\n",
    "    def get_embedding(self, text: str, model: str) -> List[float]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @classmethod\n",
    "    def cosine_similarity(cls, vector1: List[float], vector2: List[float]) -> float:\n",
    "        \"\"\"\n",
    "        calculate cosine similarity between two vectors\n",
    "        \"\"\"\n",
    "        dot_product = np.dot(vector1, vector2)\n",
    "        magnitude = np.linalg.norm(vector1) * np.linalg.norm(vector2)\n",
    "        if not magnitude:\n",
    "            return 0\n",
    "        return dot_product / magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "100f7354-a02d-4522-8228-8c7d6255b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MindNLPEmbedding(BaseEmbeddings):\n",
    "    \"\"\"\n",
    "    class for MindNLP embeddings\n",
    "    \"\"\"\n",
    "    def __init__(self, path: str = 'BAAI/bge-base-zh-v1.5', is_api: bool = False) -> None:\n",
    "        super().__init__(path, is_api)\n",
    "        self._model = self.load_model(path)\n",
    "\n",
    "    def get_embedding(self, text: str):\n",
    "        sentence_embedding = self._model.encode([text], normalize_embeddings=True)\n",
    "        return sentence_embedding\n",
    "\n",
    "    def load_model(self, path: str):\n",
    "        from mindnlp.sentence import SentenceTransformer\n",
    "        model = SentenceTransformer(path)\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def cosine_similarity(cls, sentence_embedding_1, sentence_embedding_2):\n",
    "        \"\"\"\n",
    "        calculate similarity between two vectors\n",
    "        \"\"\"\n",
    "        similarity = sentence_embedding_1 @ sentence_embedding_2.T\n",
    "        return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41f060f5-9b2c-412c-8701-87adb26e2f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name BAAI/bge-base-zh-v1.5. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = MindNLPEmbedding(\"BAAI/bge-base-zh-v1.5\")\n",
    "embedding._model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed529bd-fb9d-46bb-b2cd-fb76252c0899",
   "metadata": {},
   "source": [
    "# 4. 知识库设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d8842f6-d3d5-4a31-bd9b-f4bd6e618cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "    def __init__(self, document: List[str] = ['']) -> None:\n",
    "        self.document = document\n",
    "\n",
    "    def get_vector(self, EmbeddingModel: BaseEmbeddings):\n",
    "        self.vectors = []\n",
    "        for doc in tqdm(self.document, desc=\"Calculating embeddings\"):\n",
    "            self.vectors.append(EmbeddingModel.get_embedding(doc))\n",
    "        return self.vectors\n",
    "\n",
    "    def persist(self, path: str = 'storage'):\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        with open(f\"{path}/document.json\", 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.document, f, ensure_ascii=False)\n",
    "        if self.vectors:\n",
    "            # 将 numpy.ndarray 转换为列表\n",
    "            vectors_list = [vector.tolist() for vector in self.vectors]\n",
    "            with open(f\"{path}/vectors.json\", 'w', encoding='utf-8') as f:\n",
    "                json.dump(vectors_list, f)\n",
    "\n",
    "    def load_vector(self, EmbeddingModel: BaseEmbeddings, path: str = 'storage'):\n",
    "        with open(f\"{path}/vectors.json\", 'r', encoding='utf-8') as f:\n",
    "            vectors_list = json.load(f)\n",
    "        with open(f\"{path}/document.json\", 'r', encoding='utf-8') as f:\n",
    "            self.document = json.load(f)\n",
    "\n",
    "        # 查询 EmbeddingModel 的类别\n",
    "        if isinstance(EmbeddingModel, MindNLPEmbedding):\n",
    "            # 将列表重新变为 numpy.ndarray\n",
    "            self.vectors = [np.array(vector) for vector in vectors_list]\n",
    "        else:\n",
    "            self.vectors = vectors_list\n",
    "\n",
    "    def get_similarity(self, vector1, vector2, EmbeddingModel: BaseEmbeddings):\n",
    "        return EmbeddingModel.cosine_similarity(vector1, vector2)\n",
    "\n",
    "    def query(self, query: str, EmbeddingModel: BaseEmbeddings, k: int = 1):\n",
    "        # 获取查询字符串的嵌入向量\n",
    "        query_vector = EmbeddingModel.get_embedding(query)\n",
    "\n",
    "        # 计算查询向量与数据库中每个向量的相似度\n",
    "        similarities = [self.get_similarity(query_vector, vector, EmbeddingModel) for vector in self.vectors]\n",
    "\n",
    "        # 将相似度、向量和文档存储在一个列表中\n",
    "        results = []\n",
    "        for similarity, vector, document in zip(similarities, self.vectors, self.document):\n",
    "            results.append({\n",
    "                'similarity': similarity,\n",
    "                'vector': vector,\n",
    "                'document': document\n",
    "            })\n",
    "        # 按相似度从高到低排序\n",
    "        results.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "        # 获取最相似的 k 个文档\n",
    "        top_k_documents = [result['document'] for result in results[:k]]\n",
    "\n",
    "        return top_k_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8c27994-f794-4494-86e7-758170ab710c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name BAAI/bge-base-zh-v1.5. Creating a new one with MEAN pooling.\n",
      "Calculating embeddings: 100%|██████████| 30/30 [00:10<00:00,  2.99it/s]\n"
     ]
    }
   ],
   "source": [
    "vector = VectorStore(text)\n",
    "vector.get_vector(EmbeddingModel=embedding)\n",
    "vector.persist(path='storage')  # 将向量和文档内容保存到storage目录下，下次再用就可以直接加载本地的数据库\n",
    "vector.load_vector(EmbeddingModel=embedding, path='./storage')  # 加载本地的数据库"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4274bbf9-dd8e-480f-8af6-6a29e9c9535a",
   "metadata": {},
   "source": [
    "# 5. 大语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c183fe75-8fa1-4af9-93b3-b526e8555d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    def __init__(self, path: str = '') -> None:\n",
    "        self.path = path\n",
    "\n",
    "    def chat(self, prompt: str, history: List[dict], content: str) -> str:\n",
    "        pass\n",
    "\n",
    "    def load_model(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3582e6bd-000c-4110-8f34-73232e1a8cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = dict(\n",
    "    RAG_PROMPT_TEMPALTE=\"\"\"使用以上下文来回答用户的问题。如果你不知道答案，请输出我不知道。总是使用中文回答。\n",
    "        问题: {question}\n",
    "        可参考的上下文：\n",
    "        ···\n",
    "        {context}\n",
    "        ···\n",
    "        如果给定的上下文无法让你做出回答，请回答数据库中没有这个内容，你不知道。\n",
    "        有用的回答:\"\"\",\n",
    "    MindNLP_PROMPT_TEMPALTE=\"\"\"先对上下文进行内容总结,再使用上下文来回答用户的问题。如果你不知道答案，请输出我不知道。总是使用中文回答。\n",
    "        问题: {question}\n",
    "        可参考的上下文：\n",
    "        ···\n",
    "        {context}\n",
    "        ···\n",
    "        如果给定的上下文无法让你做出回答，请回答数据库中没有这个内容，你不知道。\n",
    "        有用的回答:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "718f2e62-8814-495a-97d7-479853bd6cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MindNLPChat(BaseModel):\n",
    "    def __init__(self, path: str = '') -> None:\n",
    "        super().__init__(path)\n",
    "        self.load_model()\n",
    "\n",
    "    def chat(self, prompt: str, history: List = [], content: str = '') -> str:\n",
    "        prompt = PROMPT_TEMPLATE['MindNLP_PROMPT_TEMPALTE'].format(question=prompt, context=content)\n",
    "        response, history = self.model.chat(self.tokenizer, prompt, history, max_length=512)\n",
    "        return response\n",
    "\n",
    "    def load_model(self):\n",
    "        import mindspore\n",
    "        from mindnlp.transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.path, mirror=\"huggingface\")\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(self.path, ms_dtype=mindspore.float16, mirror=\"huggingface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f31417d4-2aa0-4183-a9e3-8532fb2b26f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.290 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "No sentence-transformers model found with name BAAI/bge-base-zh-v1.5. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MS_ALLOC_CONF]Runtime config:  enable_vmm:True  vmm_align_size:2MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 100%|██████████| 30/30 [00:08<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['远程仓库，可以使用gitpush命令。通常，这个命令后面会跟远程仓库的名称和要推送的分支名称。\\nbash\\ngitpush<remote-name><branch-name>\\n例如，将本地的master分支推送到origin远程仓库：\\nbash\\ngitpushoriginmaster\\n从远程仓库拉取\\n从远程仓库获取最新的更改并合并到本地分支，可以使用gitpull命令。这个命令会将远程仓库的指定分支的更改拉取到当前分支。bash\\ngitpull<remote-name><branch-name>\\n例如，从origin远程仓库的master分支拉取最新更改：\\nbash\\ngitpulloriginmaster\\n远程分支管理\\n查看远程分支，可以使用gitbranch命令加上-r选项。\\nbash\\ngitbranch-r\\n删除远程分支，可以使用gitpush命令加上--delete选项。\\nbash\\ngitpush<remote-name>--delete<branch-name>\\n例如，删除origin远程仓库的feature分支：\\nbash\\ngitpushorigin--deletefeature\\n远程仓库的协作与贡献\\n协作和贡献通常涉及以下步骤：\\n\\nFork远程仓库。\\nCloneFork后的仓库到本地。\\n创建新的分支进行开发。\\n完成开发后，将分支推送到自己的Fork仓库。\\n']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MiniCPMForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`.`PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The `seen_tokens` attribute is deprecated.41. Use the `cache_position` model input instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "要使用Git新建分支，首先需要确保已经安装了Git。新建分支的步骤如下：\n",
      "\n",
      "1. 打开终端或命令提示符。\n",
      "2. 切换到你想要创建分支的仓库。\n",
      "3. 使用`git checkout -b <分支名>`命令创建一个新的分支。例如，如果你想要创建一个名为\"new-feature\"的分支，你可以输入以下命令：\n",
      "\n",
      "```\n",
      "git checkout -b new-feature\n",
      "```\n",
      "\n",
      "4. 现在，你已经在本地仓库中创建了一个名为\"new-feature\"的新分支。\n",
      "\n",
      "如果你想要将这个分支推送到远程仓库，可以使用`git push`命令。例如，如果你想要将\"new-feature\"分支推送到origin远程仓库，你可以输入以下命令：\n"
     ]
    }
   ],
   "source": [
    "# 没有保存数据库\n",
    "docs = ReadFiles('./data').get_content(max_token_len=600, cover_content=150)  # 获得data目录下的所有文件内容并分割\n",
    "vector = VectorStore(docs)\n",
    "embedding = MindNLPEmbedding(\"BAAI/bge-base-zh-v1.5\")  # 创建EmbeddingModel\n",
    "vector.get_vector(EmbeddingModel=embedding)\n",
    "vector.persist(path='storage')  # 将向量和文档内容保存到storage目录下，下次再用就可以直接加载本地的数据库\n",
    "\n",
    "vector.load_vector(EmbeddingModel=embedding, path='./storage')  # 加载本地的数据库\n",
    "\n",
    "question = 'git如何新建分支？'\n",
    "\n",
    "content = vector.query(question, EmbeddingModel=embedding, k=1)\n",
    "print(content)\n",
    "chat = MindNLPChat(path='openbmb/MiniCPM-2B-dpo-bf16')\n",
    "print(chat.chat(question, [], content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbc9b92-c436-4f83-b12d-6e5f660ecb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据库之后\n",
    "vector = VectorStore()\n",
    "vector.load_vector(EmbeddingModel=embedding, path='./storage')  # 加载本地的数据库\n",
    "question = 'git如何新建分支？'\n",
    "content = vector.query(question, EmbeddingModel=embedding, k=3)[0]\n",
    "print(content)\n",
    "chat = MindNLPChat(path='openbmb/MiniCPM-2B-dpo-bf16')\n",
    "print(chat.chat(question, [], content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87d1dd1-1fd0-43aa-8f7f-0bc04ff27e31",
   "metadata": {},
   "source": [
    "# 6. Rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98a8684a-e423-4438-9efa-1e012fb76f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseReranker:\n",
    "    \"\"\"\n",
    "    Base class for reranker\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path: str) -> None:\n",
    "        self.path = path\n",
    "\n",
    "    def rerank(self, text: str, content: List[str], k: int) -> List[str]:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adc007b3-429a-467a-bdf8-2348d251456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MindNLPReranker(BaseReranker):\n",
    "    \"\"\"\n",
    "    class for MindNLP reranker\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path: str = 'BAAI/bge-reranker-base') -> None:\n",
    "        super().__init__(path)\n",
    "        self._model= self.load_model(path)\n",
    "\n",
    "    def rerank(self, text: str, content: List[str], k: int) -> List[str]:\n",
    "        query_embedding = self._model.encode(text, normalize_embeddings=True)\n",
    "        sentences_embedding = self._model.encode(sentences=content, normalize_embeddings=True)\n",
    "        similarity = query_embedding @ sentences_embedding.T\n",
    "        # 获取按相似度排序后的索引\n",
    "        ranked_indices = np.argsort(similarity)[::-1]  # 按相似度降序排序\n",
    "        # 选择前 k 个最相关的候选内容\n",
    "        top_k_sentences = [content[i] for i in ranked_indices[:k]]\n",
    "        return top_k_sentences\n",
    "\n",
    "    def load_model(self, path: str):\n",
    "        from mindnlp.sentence import SentenceTransformer\n",
    "        model = SentenceTransformer(path)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e03dd0ef-d80b-4d91-a527-d335fa8c3ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name BAAI/bge-reranker-base. Creating a new one with MEAN pooling.\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at BAAI/bge-reranker-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['远程仓库，可以使用gitpush命令。通常，这个命令后面会跟远程仓库的名称和要推送的分支名称。\\nbash\\ngitpush<remote-name><branch-name>\\n例如，将本地的master分支推送到origin远程仓库：\\nbash\\ngitpushoriginmaster\\n从远程仓库拉取\\n从远程仓库获取最新的更改并合并到本地分支，可以使用gitpull命令。这个命令会将远程仓库的指定分支的更改拉取到当前分支。bash\\ngitpull<remote-name><branch-name>\\n例如，从origin远程仓库的master分支拉取最新更改：\\nbash\\ngitpulloriginmaster\\n远程分支管理\\n查看远程分支，可以使用gitbranch命令加上-r选项。\\nbash\\ngitbranch-r\\n删除远程分支，可以使用gitpush命令加上--delete选项。\\nbash\\ngitpush<remote-name>--delete<branch-name>\\n例如，删除origin远程仓库的feature分支：\\nbash\\ngitpushorigin--deletefeature\\n远程仓库的协作与贡献\\n协作和贡献通常涉及以下步骤：\\n\\nFork远程仓库。\\nCloneFork后的仓库到本地。\\n创建新的分支进行开发。\\n完成开发后，将分支推送到自己的Fork仓库。\\n', 'checkout<branch_name>\\n这将使当前工作目录切换到名为<branch_name>的分支上。\\n合并分支\\n要将一个分支的更改合并到当前分支，可以使用以下命令：\\nbash\\ngitmerge<branch_name>\\n这将把名为<branch_name>的分支合并到当前分支上。\\n解决冲突\\n在合并分支时，如果发生冲突，需要手动解决冲突。可以通过编辑文件来解决冲突，然后使用以下命令标记文件为已解决冲突的状态：bash\\ngitadd<file_name>\\n解决完所有冲突后，可以继续合并分支。\\n以上是关于Git分支管理的基本操作。\\n远程仓库\\n添加远程仓库\\n要将本地仓库与远程仓库关联，可以使用以下命令：\\nbash\\ngitremoteaddorigin远程仓库地址\\n其中，origin是远程仓库的别名，可以根据实际情况自行命名。\\n推送到远程仓库\\n将本地提交推送到远程仓库可以使用以下命令：\\nbash\\ngitpushorigin分支名\\n例如，将本地的master分支推送到远程仓库可以使用：\\nbash\\ngitpushoriginmaster\\n从远程仓库拉取\\n从远程仓库拉取最新代码到本地可以使用以下命令：\\nbash\\ngitpullorigin分支名\\n', '是用来隔离开发工作的。每个分支都是一个独立的开发环境，互不影响。分支可以很方便地被创建和合并，因此许多开发者使用分支来进行特性开发、修复bug或者尝试新想法。\\nGit的一个核心概念是几乎所有操作都是本地执行的，分支也不例外。这意味着你在本地创建或切换分支，不需要与远程仓库进行通信。\\n创建与合并分支\\n在Git中创建新分支可以使用gitbranch命令，合并分支则使用gitmerge命令。```bash\\n创建新分支\\ngitbranch\\n切换到新分支\\ngitcheckout\\n创建新分支并立即切换到该分支\\ngitcheckout-b\\n合并指定分支到当前分支\\ngitmerge\\n```\\n分支策略\\n合理的分支策略可以帮助团队更有效地协作。一种常见的策略是GitFlow，它定义了一个围绕项目发布的分支模型，包括功能分支、发布分支、维护分支等。\\n另一种策略是GitHubFlow，它更加简单灵活，适合持续交付的项目。在GitHubFlow中，master分支通常是稳定的，并且随时可以部署。所有新的开发都在基于master的特性分支上进行，一旦完成就可以合并回master。\\n解决冲突\\n']\n"
     ]
    }
   ],
   "source": [
    "# 创建RerankerModel\n",
    "reranker = MindNLPReranker('BAAI/bge-reranker-base')\n",
    "\n",
    "vector = VectorStore()\n",
    "vector.load_vector(EmbeddingModel=embedding, path='./storage')  # 加载本地的数据库\n",
    "\n",
    "question = 'git如何新建分支？'\n",
    "\n",
    "# 从向量数据库中查询出最相似的3个文档\n",
    "content = vector.query(question, EmbeddingModel=embedding, k=3)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31faa8d0-29b8-429c-86f7-764b408f70c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['是用来隔离开发工作的。每个分支都是一个独立的开发环境，互不影响。分支可以很方便地被创建和合并，因此许多开发者使用分支来进行特性开发、修复bug或者尝试新想法。\\nGit的一个核心概念是几乎所有操作都是本地执行的，分支也不例外。这意味着你在本地创建或切换分支，不需要与远程仓库进行通信。\\n创建与合并分支\\n在Git中创建新分支可以使用gitbranch命令，合并分支则使用gitmerge命令。```bash\\n创建新分支\\ngitbranch\\n切换到新分支\\ngitcheckout\\n创建新分支并立即切换到该分支\\ngitcheckout-b\\n合并指定分支到当前分支\\ngitmerge\\n```\\n分支策略\\n合理的分支策略可以帮助团队更有效地协作。一种常见的策略是GitFlow，它定义了一个围绕项目发布的分支模型，包括功能分支、发布分支、维护分支等。\\n另一种策略是GitHubFlow，它更加简单灵活，适合持续交付的项目。在GitHubFlow中，master分支通常是稳定的，并且随时可以部署。所有新的开发都在基于master的特性分支上进行，一旦完成就可以合并回master。\\n解决冲突\\n', 'checkout<branch_name>\\n这将使当前工作目录切换到名为<branch_name>的分支上。\\n合并分支\\n要将一个分支的更改合并到当前分支，可以使用以下命令：\\nbash\\ngitmerge<branch_name>\\n这将把名为<branch_name>的分支合并到当前分支上。\\n解决冲突\\n在合并分支时，如果发生冲突，需要手动解决冲突。可以通过编辑文件来解决冲突，然后使用以下命令标记文件为已解决冲突的状态：bash\\ngitadd<file_name>\\n解决完所有冲突后，可以继续合并分支。\\n以上是关于Git分支管理的基本操作。\\n远程仓库\\n添加远程仓库\\n要将本地仓库与远程仓库关联，可以使用以下命令：\\nbash\\ngitremoteaddorigin远程仓库地址\\n其中，origin是远程仓库的别名，可以根据实际情况自行命名。\\n推送到远程仓库\\n将本地提交推送到远程仓库可以使用以下命令：\\nbash\\ngitpushorigin分支名\\n例如，将本地的master分支推送到远程仓库可以使用：\\nbash\\ngitpushoriginmaster\\n从远程仓库拉取\\n从远程仓库拉取最新代码到本地可以使用以下命令：\\nbash\\ngitpullorigin分支名\\n']\n"
     ]
    }
   ],
   "source": [
    "# 从一阶段查询结果中用Reranker再次筛选出最相似的2个文档\n",
    "rerank_content = reranker.rerank(question, content, k=2)\n",
    "print(rerank_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13fd324d-6345-40a4-9a58-4cf847b6a99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "要使用Git新建分支，你可以使用`git branch`命令。首先，输入以下命令创建一个新的分支：\n",
      "\n",
      "```bash\n",
      "git branch new-branch-name\n",
      "```\n",
      "\n",
      "其中`new-branch-name`是你想要为分支命名的名称。然后，输入以下命令将新分支切换到你刚刚创建的分支上：\n",
      "\n",
      "```bash\n",
      "git checkout new-branch-name\n",
      "```\n",
      "\n",
      "现在，你可以开始在你的新分支上进行开发工作。如果需要将新分支合并回主分支，可以使用`git merge`命令。例如，如果你想要将新分支合并回主分支，你可以输入以下命令：\n",
      "\n",
      "```bash\n",
      "git merge master\n",
      "```\n",
      "\n",
      "其中`master`是你主分支的名称。\n",
      "\n",
      "请注意，在合并分支时，可能会发生冲突。这时，你需要手动解决冲突，确保所有更改都被正确地合并。\n"
     ]
    }
   ],
   "source": [
    "# 最后选择最相似的文档, 交给LLM作为可参考上下文\n",
    "best_content = rerank_content[0]\n",
    "print(chat.chat(question, [], best_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d30e63-ff12-4241-a468-f022e8471803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
